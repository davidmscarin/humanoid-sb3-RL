{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Behavior Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook serves to visualize agent behavior after training\n",
    "we visualize the behavior of 4 agents:\n",
    "- agent without training\n",
    "- agent trained on default environment\n",
    "- agent trained on changed environment after 1st phase of training\n",
    "- agent trained on changed environment after 2nd phase of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "from stable_baselines3 import PPO, TD3\n",
    "import time\n",
    "import gymnasium as gym\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Env no training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gym.make(\"Humanoid-v4\", render_mode = \"human\", healthy_z_range=(0.9,2.0))\n",
    "wrapped_env_test = gym.wrappers.RecordEpisodeStatistics(env_test)\n",
    "agent = PPO('MlpPolicy', wrapped_env_test, verbose=0)\n",
    "seed = 42\n",
    "\n",
    "for episode in range(10):\n",
    "    obs, info = wrapped_env_test.reset(seed=seed)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _states = agent.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = wrapped_env_test.step(action)\n",
    "        done = terminated or truncated\n",
    "        wrapped_env_test.render()\n",
    "            \n",
    "env_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Env Agent 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gym.make(\"Humanoid-v4\", render_mode = \"human\", healthy_z_range=(0.9,2.0))\n",
    "wrapped_env_test = gym.wrappers.RecordEpisodeStatistics(env_test)\n",
    "agent = PPO.load(\"agents//agent_default_1\", env = wrapped_env_test)\n",
    "seed = 42\n",
    "\n",
    "for episode in range(10):\n",
    "    obs, info = wrapped_env_test.reset(seed=seed)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _states = agent.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = wrapped_env_test.step(action)\n",
    "        done = terminated or truncated\n",
    "        wrapped_env_test.render()\n",
    "            \n",
    "env_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed Env 1st Phase of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gym.make(\"Humanoid-v4\", render_mode = \"human\", healthy_z_range=(0.9,2.0))\n",
    "wrapped_env_test = gym.wrappers.RecordEpisodeStatistics(env_test)\n",
    "agent = PPO.load(\"agents//agent_changed_1_1\", env = wrapped_env_test)\n",
    "seed = 42\n",
    "\n",
    "for episode in range(10):\n",
    "    obs, info = wrapped_env_test.reset(seed=seed)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _states = agent.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = wrapped_env_test.step(action)\n",
    "        done = terminated or truncated\n",
    "        wrapped_env_test.render()\n",
    "            \n",
    "env_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed Env 2nd Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = gym.make(\"Humanoid-v4\", render_mode = \"human\", healthy_z_range=(0.9,2.0))\n",
    "wrapped_env_test = gym.wrappers.RecordEpisodeStatistics(env_test)\n",
    "agent = PPO.load(\"agents//agent_changed_2_1\", env = wrapped_env_test)\n",
    "seed = 42\n",
    "\n",
    "for episode in range(10):\n",
    "    obs, info = wrapped_env_test.reset(seed=seed)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _states = agent.predict(obs)\n",
    "        obs, reward, terminated, truncated, info = wrapped_env_test.step(action)\n",
    "        done = terminated or truncated\n",
    "        wrapped_env_test.render()\n",
    "            \n",
    "env_test.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
